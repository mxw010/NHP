---
title: "NHP Amplicons QCs"
author: "Meng Wang"
date: "`r format(Sys.time(), '%B %d, %Y')`"
execute:
        cache: true
format:
        html:
            code-fold: true
            code-overflow: "wrap"
            embed-resources: true
            tidy: true
            code-link: false
editor_options:
  chunk_output_type: console
---



```{r}
suppressPackageStartupMessages(library(data.table))
suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(ggplot2))
suppressPackageStartupMessages(library(gt))
suppressPackageStartupMessages(library(patchwork))
suppressPackageStartupMessages(library(rjson))
```

# QC
- Raw Reads: Number of reads (DNA sequences) for both R1 and R2 in the fastq files.
- Extracted: After matching the flanking sequences, number of DNA Sequences extracted.
- After QC: Number of DNA sequences after QC filtering (R1 and R2 agreement, quality score >30).
- Invalid NNK: Number of DNA sequences with invalid NNK (K are not G or T) patterns.
- Stop Codons: Number of DNA with stop codons.

```{r}

parse_json <- function(json_file) {
    temp <- fromJSON(file = json_file)[-(1:3)]
    info <- str_split_1(temp$output,"/") %>%
                tail(1) %>%
                str_split_1("_")
    temp$capsid <- info[1]
    temp$sample <- str_split_i(info[2], "-", i=2)
    temp$read <- info[3]
    return(temp)
}


temp <- sapply(list.files(path="/igm/home/mxw010/NHP/data/sciatic_nerve", pattern="*summary.txt", full.names = TRUE), parse_json, simplify=FALSE)

df <- bind_rows(temp) %>% 
        # rownames_to_column('file_name') %>%
        select(`total_reads`, `matched_flanking`, `capsid`, `sample`, `read`) %>%
        pivot_wider(names_from='read', values_from=matched_flanking) %>%
        mutate(ID = paste0(capsid, tolower(sample)))
        
clean_qc <- read.csv('/igm/home/mxw010/NHP/data/sciatic_nerve/processed/summary.csv') %>%
            mutate(ID = paste0(Capsid, tolower(Sample)))

merge(df, clean_qc, by.x=6, by.y=6) %>%
  as_tibble() %>%
  select(-ID, -capsid, -sample) %>% 
  relocate(Sample, Capsid) %>%
  rename(Total = total_reads) %>%
  rename(R1_Extracted = R1) %>%
  rename(R2_Extracted = R2) %>%
  rename(After_QC = Reads) %>%
  mutate(Total = as.integer(Total)) %>%
  mutate(R1_Extracted = as.integer(R1_Extracted)) %>%
  mutate(R2_Extracted = as.integer(R2_Extracted)) %>%
  gt(groupname_col = "Sample") %>%
  cols_label(R1_Extracted = "R1 Extracted") %>%
  cols_label(R2_Extracted = "R2 Extracted") %>%
  cols_label(After_QC = "After QC") %>%
  cols_label(Invalid_NNK = "Invalid NNK") %>%
  cols_label(Stop_Codons = "Stop Codons") %>%
  cols_label(Total = "Raw Reads") %>%
  fmt_number(columns=!starts_with('Capsid'), decimals=0)
```

# Peptide Counts
Those are the counts for for each capsid after QC filtering.
```{r}
read.csv('/igm/home/mxw010/NHP/data/sciatic_nerve/processed/peptide_counts.csv') %>%
  pivot_wider(names_from="Sample", values_from="Peptide_Counts") %>%
  gt(rowname_col="Capsid")

```

# Enrichment Calculation

- SC and Input counts are raw counts (not normalized)
- I only retained peptides with counts > 20 (in the SC sample) for analysis.
- If the peptide is not in the input sample, it is given a nominal count of 1 for Enrichment calculation.
- The Enrichment score is calculated as normalized SC counts / normalized Input counts, where the counts are normalized by the total peptide counts for each sample.

# Github repo Associated with this project:
https://github.com/mxw010/NHP